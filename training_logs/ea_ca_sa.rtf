{\rtf1\ansi\ansicpg1252\deff0\deflang1033{\fonttbl{\f0\fmodern Consolas;}{\f1\fnil\fcharset129 Courier New;}}
{\colortbl ;\red20\green20\blue20;\red142\green142\blue142;\red18\green124\blue155;\red127\green195\blue235;\red0\green90\blue143;}
\viewkind4\uc1\pard\f0\fs20 ubuntu@cv2:~/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics$ python3 train.py\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary: 99 layers, 2,869,258 parameters, 2,869,258 gradients\cf1\highlight2 
\par \cf0\highlight0 New https://pypi.org/project/ultralytics/8.3.100 available \u55357?\u56835? Update with 'pip install -U ultralytics'\cf1\highlight2 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf3\highlight0 engine/trainer: \cf0 task=classify, mode=train, model=yolo11n-cls.yaml, data=data, epochs=50, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=10, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... found 6101 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... found 714 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/test... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf0\highlight0 Overriding model.yaml nc=1000 with nc=4\cf1\highlight2 
\par 
\par \cf0\highlight0                    from  n    params  module                                       arguments\cf1\highlight2 
\par \cf0\highlight0   0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]\cf1\highlight2 
\par \cf0\highlight0   3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]\cf1\highlight2 
\par \cf0\highlight0   5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]\cf1\highlight2 
\par \cf0\highlight0   7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]\cf1\highlight2 
\par \cf0\highlight0   9                  -1  1    306882  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]\cf1\highlight2 
\par \cf0\highlight0  10                  -1  1    335364  ultralytics.nn.modules.head.Classify         [256, 4]\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary: 99 layers, 1,593,382 parameters, 1,593,382 gradients\cf1\highlight2 
\par \cf3\highlight0 AMP: \cf0 running Automatic Mixed Precision (AMP) checks...\cf1\highlight2 
\par \cf3\highlight0 AMP: \cf0 checks skipped \u9888?\cf4\highlight4\u65039?\cf0\highlight0 . Unable to load YOLO11n for AMP checks due to possible Ultralytics package modifications. Setting 'amp=True'. If you experience zero-mAP or NaN losses you can disable AMP with amp=False.\cf1\highlight2 
\par \cf3\highlight0 train: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... 6101 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 6101/6101 [00:00\cf1\highlight2 
\par \cf3\highlight0 val: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... 714 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 714/714 [00:00<?, ?it\cf1\highlight2 
\par \cf3\highlight0 optimizer:\cf0  SGD(lr=0.0001, momentum=0.937) with parameter groups 40 weight(decay=0.0), 47 weight(decay=0.0005), 43 bias(decay=0.0)\cf1\highlight2 
\par \cf0\highlight0 Image sizes 512 train, 512 val\cf1\highlight2 
\par \cf0\highlight0 Using 8 dataloader workers\cf1\highlight2 
\par \cf0\highlight0 Logging results to \b /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train\cf1\highlight2\b0 
\par \cf0\highlight0 Starting training for 50 epochs...\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        1/50      1.08G      1.177          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:18<00:00, 20.59it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.17it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.338          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        2/50      1.14G       1.12          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.70it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.19it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.391          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        3/50      1.14G     0.9944          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.81it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.72it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.724          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        4/50      1.14G     0.8632          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.08it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.29it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.754          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        5/50      1.14G     0.8154          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.92it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.26it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.754          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        6/50      1.14G     0.7839          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.56it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.69it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.744          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        7/50      1.14G     0.7569          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.38it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.64it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.756          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        8/50      1.14G     0.7366          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.52it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.71it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.761          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        9/50      1.14G     0.7104          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.49it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.62it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.718          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       10/50      1.14G     0.7038          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.85it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.95it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.765          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       11/50      1.14G     0.6865          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.80it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.50it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.756          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       12/50      1.14G     0.6702          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.28it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.58it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.768          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       13/50      1.14G      0.675          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.46it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.77it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.776          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       14/50      1.14G     0.6562          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.45it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.39it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.783          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       15/50      1.14G     0.6507          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.69it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.99it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.789          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       16/50      1.14G     0.6442          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.19it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.88it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.766          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       17/50      1.14G     0.6368          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.30it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.66it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.738          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       18/50      1.14G     0.6327          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.53it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.25it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.777          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       19/50      1.14G     0.6295          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.20it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.64it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.763          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       20/50      1.14G     0.6197          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.01it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.31it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.793          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       21/50      1.14G     0.6179          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.32it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.36it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.793          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       22/50      1.14G     0.6085          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.20it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.45it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.759          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       23/50      1.14G     0.6026          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.96it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.26it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.777          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       24/50      1.14G      0.602          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.05it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.52it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.759          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       25/50      1.14G     0.6033          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.28it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.55it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.801          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       26/50      1.14G     0.5949          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.91it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.47it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.794          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       27/50      1.14G     0.5952          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.05it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.91it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.786          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       28/50      1.14G     0.5943          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.11it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.88it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.789          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       29/50      1.14G     0.5819          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.86it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 32.30it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.793          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       30/50      1.14G     0.5789          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.52it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.55it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.801          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       31/50      1.14G     0.5902          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.92it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.26it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.791          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       32/50      1.14G     0.5805          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.64it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.82it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.772          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       33/50      1.14G     0.5903          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.92it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.90it/s]\cf1\highlight2 
\par \cf0\highlight0                    all        0.8          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       34/50      1.14G     0.5814          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.95it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.08it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.782          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       35/50      1.14G      0.577          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.86it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.89it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.794          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       36/50      1.14G     0.5669          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.96it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.14it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.793          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       37/50      1.14G     0.5736          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.20it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.07it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.78          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       38/50      1.14G     0.5688          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.03it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.88it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.779          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       39/50      1.14G     0.5654          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.75it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.16it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.808          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       40/50      1.14G     0.5619          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.20it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.41it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.801          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       41/50      1.14G     0.5648          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.49it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.94it/s]\cf1\highlight2 
\par \cf0\highlight0                    all        0.8          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       42/50      1.14G     0.5695          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.15it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.02it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.801          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       43/50      1.14G     0.5593          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.28it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.01it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.812          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       44/50      1.14G     0.5569          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.62it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.93it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.807          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       45/50      1.14G     0.5558          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.99it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.36it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.807          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       46/50      1.14G     0.5707          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.30it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.65it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.805          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       47/50      1.14G     0.5598          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.77it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.11it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.796          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       48/50      1.14G       0.56          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.70it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.11it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.814          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       49/50      1.14G      0.558          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.94it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.44it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.81          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       50/50      1.14G     0.5557          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.33it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.69it/s]\cf1\highlight2 
\par \cf0\highlight0                    all        0.8          1\cf1\highlight2 
\par 
\par \cf0\highlight0 50 epochs completed in 0.231 hours.\cf1\highlight2 
\par \cf0\highlight0 Optimizer stripped from /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train/weights/last.pt, 3.3MB\cf1\highlight2 
\par \cf0\highlight0 Optimizer stripped from /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train/weights/best.pt, 3.3MB\cf1\highlight2 
\par 
\par \cf0\highlight0 Validating /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train/weights/best.pt...\cf1\highlight2 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary (fused): 60 layers, 1,588,302 parameters, 0 gradients\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... found 6101 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... found 714 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/test... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:01<00:00, 22.73it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.814          1\cf1\highlight2 
\par \cf0\highlight0 Speed: 0.4ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\cf1\highlight2 
\par \cf0\highlight0 Results saved to \b /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train\cf1\highlight2\b0 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary (fused): 60 layers, 1,588,302 parameters, 0 gradients\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/vald/train... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/vald/val... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  None...\cf1\highlight2 
\par \cf3\highlight0 val: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/vald/val... 357 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 357/357 [00:00<00:00,\cf1\highlight2 
\par \cf3\highlight0 val: \cf0 New cache created: /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/vald/val.cache\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:01<00:00, 18.36it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.784          1\cf1\highlight2 
\par \cf0\highlight0 Speed: 0.7ms preprocess, 1.2ms inference, 0.0ms loss, 0.0ms postprocess per image\cf1\highlight2 
\par \cf0\highlight0 Results saved to \b /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train2\cf1\highlight2\b0 
\par \cf0\highlight0 ubuntu@cv2:~/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics$ python3 train.py\cf1\highlight2 
\par \cf0\highlight0 Creating new Ultralytics Settings v0.0.6 file \u9989?\cf1\highlight2 
\par \cf0\highlight0 View Ultralytics Settings with 'yolo settings' or at '/home/ubuntu/.config/Ultralytics/settings.json'\cf1\highlight2 
\par \cf0\highlight0 Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary: 99 layers, 2,869,258 parameters, 2,869,258 gradients\cf1\highlight2 
\par \cf0\highlight0 New https://pypi.org/project/ultralytics/8.3.100 available \u55357?\u56835? Update with 'pip install -U ultralytics'\cf1\highlight2 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf3\highlight0 engine/trainer: \cf0 task=classify, mode=train, model=yolo11n-cls.yaml, data=data, epochs=50, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=10, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train3\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... found 6101 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... found 714 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/test... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf0\highlight0 Overriding model.yaml nc=1000 with nc=4\cf1\highlight2 
\par 
\par \cf0\highlight0                    from  n    params  module                                       arguments\cf1\highlight2 
\par \cf0\highlight0   0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]\cf1\highlight2 
\par \cf0\highlight0   3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]\cf1\highlight2 
\par \cf0\highlight0   5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]\cf1\highlight2 
\par \cf0\highlight0   7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]\cf1\highlight2 
\par \cf0\highlight0   9                  -1  1    306882  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]\cf1\highlight2 
\par \cf0\highlight0  10                  -1  1    335364  ultralytics.nn.modules.head.Classify         [256, 4]\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary: 99 layers, 1,593,382 parameters, 1,593,382 gradients\cf1\highlight2 
\par \cf3\highlight0 AMP: \cf0 running Automatic Mixed Precision (AMP) checks...\cf1\highlight2 
\par \cf3\highlight0 AMP: \cf0 checks skipped \u9888?\cf4\highlight4\u65039?\cf0\highlight0 . Unable to load YOLO11n for AMP checks due to possible Ultralytics package modifications. Setting 'amp=True'. If you experience zero-mAP or NaN losses you can disable AMP with amp=False.\cf1\highlight2 
\par \cf3\highlight0 train: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... 6101 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 6101/6101 [00:00\cf1\highlight2 
\par \cf3\highlight0 val: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... 714 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 714/714 [00:00<?, ?it\cf1\highlight2 
\par \cf3\highlight0 optimizer:\cf0  'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically...\cf1\highlight2 
\par \cf3\highlight0 optimizer:\cf0  AdamW(lr=0.00125, momentum=0.9) with parameter groups 40 weight(decay=0.0), 47 weight(decay=0.0005), 43 bias(decay=0.0)\cf1\highlight2 
\par \cf0\highlight0 Image sizes 512 train, 512 val\cf1\highlight2 
\par \cf0\highlight0 Using 8 dataloader workers\cf1\highlight2 
\par \cf0\highlight0 Logging results to \b /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train3\cf1\highlight2\b0 
\par \cf0\highlight0 Starting training for 50 epochs...\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        1/50     0.984G       1.42         16        512:   0%|          | 1/382 [00:02<14:26,  2.27s/it]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        1/50      1.18G      1.373         16        512:   9%|\u9609?         | 34/382 [00:03<00:16, 20.87it/s]Downloading https://ultralytics.com/assets/Arial.ttf to '/home/ubuntu/.config/Ultralytics/Arial.ttf'...\cf1\highlight2 
\par \cf0\highlight0 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 755k/755k [00:00<00:00, 24.0MB/s]\cf1\highlight2 
\par \cf0\highlight0        1/50      1.18G     0.9146          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:19<00:00, 20.02it/s]       | 0.00/755k [00:00<?, ?B/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 26.32it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.749          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        2/50      1.18G     0.7142          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.25it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.25it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.751          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        3/50      1.18G     0.6716          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.32it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.10it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.793          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        4/50      1.18G     0.6664          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.92it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.00it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.741          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        5/50      1.18G     0.6423          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.08it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.84it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.77          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        6/50      1.18G     0.6125          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.17it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 26.07it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.793          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        7/50      1.18G     0.6074          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.86it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.12it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.804          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        8/50      1.18G     0.5941          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.65it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.60it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.783          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        9/50      1.18G     0.5802          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.07it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.75it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.803          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       10/50      1.18G     0.5814          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.38it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.09it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.804          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       11/50      1.18G     0.5692          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.91it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.53it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.796          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       12/50      1.18G     0.5478          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.88it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 24.85it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.819          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       13/50      1.18G     0.5548          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.42it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.85it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.828          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       14/50      1.18G     0.5342          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.35it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 26.73it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.822          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       15/50      1.18G      0.538          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.26it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.35it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.832          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       16/50      1.18G     0.5268          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.55it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.18it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.739          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       17/50      1.18G     0.5242          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.80it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.93it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.783          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       18/50      1.18G     0.5169          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.90it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.12it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.803          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       19/50      1.18G     0.5019          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.54it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.96it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.784          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       20/50      1.18G     0.5085          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.08it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.46it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.787          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       21/50      1.18G     0.5115          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.09it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.78it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.831          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       22/50      1.18G     0.4914          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.46it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.30it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.819          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       23/50      1.18G      0.496          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.12it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.85it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.825          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       24/50      1.18G     0.4891          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.08it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.00it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.803          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       25/50      1.18G     0.4865          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.89it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.30it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.836          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       26/50      1.18G     0.4857          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.10it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.11it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.825          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       27/50      1.18G     0.4813          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.82it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.69it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.824          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       28/50      1.18G     0.4699          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.76it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.22it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.826          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       29/50      1.18G     0.4669          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.67it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.18it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.84          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       30/50      1.18G     0.4605          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.46it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.96it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.849          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       31/50      1.18G     0.4574          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.59it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.77it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.832          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       32/50      1.18G     0.4543          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.76it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.44it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.843          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       33/50      1.18G     0.4451          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.69it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.03it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.833          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       34/50      1.18G     0.4415          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.37it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 26.51it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.839          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       35/50      1.18G     0.4383          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.65it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.05it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.84          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       36/50      1.18G     0.4365          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.16it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.42it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.838          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       37/50      1.18G     0.4354          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.62it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.27it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.839          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       38/50      1.18G     0.4338          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.56it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.16it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.832          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       39/50      1.18G     0.4148          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.88it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.27it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.829          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       40/50      1.18G     0.4199          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.67it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.07it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.825          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       41/50      1.18G     0.4106          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.47it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.58it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.84          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       42/50      1.18G     0.4017          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.74it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.88it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.853          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       43/50      1.18G      0.404          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.97it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.02it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.843          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       44/50      1.18G     0.3954          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.68it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.35it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.84          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       45/50      1.18G     0.3861          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.11it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 26.98it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.833          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       46/50      1.18G     0.3977          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.71it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.77it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.835          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       47/50      1.18G     0.3918          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.95it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.02it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.842          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       48/50      1.18G     0.3819          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.88it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.77it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.843          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       49/50      1.18G     0.3721          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.91it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.89it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.84          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       50/50      1.18G     0.3731          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.86it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.24it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.84          1\cf1\highlight2 
\par 
\par \cf0\highlight0 50 epochs completed in 0.236 hours.\cf1\highlight2 
\par \cf0\highlight0 Optimizer stripped from /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train3/weights/last.pt, 3.3MB\cf1\highlight2 
\par \cf0\highlight0 Optimizer stripped from /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train3/weights/best.pt, 3.3MB\cf1\highlight2 
\par 
\par \cf0\highlight0 Validating /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train3/weights/best.pt...\cf1\highlight2 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary (fused): 60 layers, 1,588,302 parameters, 0 gradients\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... found 6101 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... found 714 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/test... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 23.97it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.854          1\cf1\highlight2 
\par \cf0\highlight0 Speed: 0.3ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\cf1\highlight2 
\par \cf0\highlight0 Results saved to \b /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train3\cf1\highlight2\b0 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary (fused): 60 layers, 1,588,302 parameters, 0 gradients\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/vald/train... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/vald/val... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  None...\cf1\highlight2 
\par \cf3\highlight0 val: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/vald/val... 357 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 357/357 [00:00<?, ?it\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:01<00:00, 17.72it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.832          1\cf1\highlight2 
\par \cf0\highlight0 Speed: 0.7ms preprocess, 1.0ms inference, 0.0ms loss, 0.0ms postprocess per image\cf1\highlight2 
\par \cf0\highlight0 Results saved to \b /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train32\cf1\highlight2\b0 
\par \cf0\highlight0 ubuntu@cv2:~/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics$ python3 train.py\cf1\highlight2 
\par \cf0\highlight0 Creating new Ultralytics Settings v0.0.6 file \u9989?\cf1\highlight2 
\par \cf0\highlight0 View Ultralytics Settings with 'yolo settings' or at '/home/ubuntu/.config/Ultralytics/settings.json'\cf1\highlight2 
\par \cf0\highlight0 Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary: 99 layers, 2,869,258 parameters, 2,869,258 gradients\cf1\highlight2 
\par \cf0\highlight0 Transferred 192/247 items from pretrained weights\cf1\highlight2 
\par \cf0\highlight0 New https://pypi.org/project/ultralytics/8.3.100 available \u55357?\u56835? Update with 'pip install -U ultralytics'\cf1\highlight2 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf3\highlight0 engine/trainer: \cf0 task=classify, mode=train, model=yolo11n-cls.yaml, data=data, epochs=50, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=models/best.pt, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=10, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train4\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... found 6101 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... found 714 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/test... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf0\highlight0 Overriding model.yaml nc=1000 with nc=4\cf1\highlight2 
\par 
\par \cf0\highlight0                    from  n    params  module                                       arguments\cf1\highlight2 
\par \cf0\highlight0   0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]\cf1\highlight2 
\par \cf0\highlight0   3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]\cf1\highlight2 
\par \cf0\highlight0   5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]\cf1\highlight2 
\par \cf0\highlight0   7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]\cf1\highlight2 
\par \cf0\highlight0   9                  -1  1    306882  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]\cf1\highlight2 
\par \cf0\highlight0  10                  -1  1    335364  ultralytics.nn.modules.head.Classify         [256, 4]\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary: 99 layers, 1,593,382 parameters, 1,593,382 gradients\cf1\highlight2 
\par \cf0\highlight0 Transferred 245/247 items from pretrained weights\cf1\highlight2 
\par \cf3\highlight0 AMP: \cf0 running Automatic Mixed Precision (AMP) checks...\cf1\highlight2 
\par \cf3\highlight0 AMP: \cf0 checks skipped \u9888?\cf5\highlight5\u65039?\cf0\highlight0 . Unable to load YOLO11n for AMP checks due to possible Ultralytics package modifications. Setting 'amp=True'. If you experience zero-mAP or NaN losses you can disable AMP with amp=False.\cf1\highlight2 
\par \cf3\highlight0 train: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... 6101 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 6101/6101 [00:00\cf1\highlight2 
\par \cf3\highlight0 val: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... 714 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 714/714 [00:00<?, ?it\cf1\highlight2 
\par \cf3\highlight0 optimizer:\cf0  'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically...\cf1\highlight2 
\par \cf3\highlight0 optimizer:\cf0  AdamW(lr=0.00125, momentum=0.9) with parameter groups 40 weight(decay=0.0), 47 weight(decay=0.0005), 43 bias(decay=0.0)\cf1\highlight2 
\par \cf0\highlight0 Image sizes 512 train, 512 val\cf1\highlight2 
\par \cf0\highlight0 Using 8 dataloader workers\cf1\highlight2 
\par \cf0\highlight0 Logging results to \b /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train4\cf1\highlight2\b0 
\par \cf0\highlight0 Starting training for 50 epochs...\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        1/50     0.977G      1.411         16        512:   0%|          | 1/382 [00:02<12:46,  2.01s/it]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        1/50      1.17G       1.38         16        512:   4%|\u9614?         | 14/382 [00:02<00:33, 11.15it/s]Downloading https://ultralytics.com/assets/Arial.ttf to '/home/ubuntu/.config/Ultralytics/Arial.ttf'...\cf1\highlight2 
\par \cf0\highlight0 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 755k/755k [00:00<00:00, 24.3MB/s]\cf1\highlight2 
\par \cf0\highlight0        1/50      1.17G     0.6833          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:18<00:00, 20.89it/s]       | 0.00/755k [00:00<?, ?B/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.00it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.821          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        2/50      1.17G       0.51          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.22it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.84it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.779          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        3/50      1.17G     0.5047          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.18it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.93it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.864          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        4/50      1.17G     0.4793          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.15it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.98it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.845          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        5/50      1.17G     0.4653          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.48it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.50it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.836          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        6/50      1.17G     0.4404          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.73it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.28it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.836          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        7/50      1.17G     0.3901         16        512:  19%|\u9608?\u9610?        | 71/382 [00:02<00:12, 24.37it/s]\cf1\highlight2 
\par \cf0\highlight0 Traceback (most recent call last):\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/train.py", line 7, in <module>\cf1\highlight2 
\par \cf0\highlight0     results = model.train(data="data", epochs=50, pretrained = 'models/best.pt', imgsz=512,close_mosaic = 0, cls = 10, dropout = 0.3)\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/engine/model.py", line 791, in train\cf1\highlight2 
\par \cf0\highlight0     self.trainer.train()\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/engine/trainer.py", line 211, in train\cf1\highlight2 
\par \cf0\highlight0     self._do_train(world_size)\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/engine/trainer.py", line 418, in _do_train\cf1\highlight2 
\par \cf0\highlight0     f"\{self._get_memory():.3g\}G",  # (GB) GPU memory util\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/engine/trainer.py", line 502, in _get_memory\cf1\highlight2 
\par \cf0\highlight0     memory = torch.cuda.memory_reserved()\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py", line 427, in memory_reserved\cf1\highlight2 
\par \cf0\highlight0     return memory_stats(device=device).get("reserved_bytes.all.current", 0)\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py", line 271, in memory_stats\cf1\highlight2 
\par \cf0\highlight0     stats = memory_stats_as_nested_dict(device=device)\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py", line 282, in memory_stats_as_nested_dict\cf1\highlight2 
\par \cf0\highlight0     device = _get_device_index(device, optional=True)\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.10/dist-packages/torch/cuda/_utils.py", line 38, in _get_device_index\cf1\highlight2 
\par \cf0\highlight0     return _torch_get_device_index(device, optional, allow_cpu)\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.10/dist-packages/torch/_utils.py", line 798, in _get_device_index\cf1\highlight2 
\par \cf0\highlight0     if torch.jit.is_scripting():\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py", line 1130, in is_scripting\cf1\highlight2 
\par \cf0\highlight0     def is_scripting() -> bool:\cf1\highlight2 
\par \cf0\highlight0 KeyboardInterrupt\cf1\highlight2 
\par 
\par \cf0\highlight0 ubuntu@cv2:~/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics$ python3 train.py\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary: 99 layers, 2,869,258 parameters, 2,869,258 gradients\cf1\highlight2 
\par \cf0\highlight0 Transferred 192/247 items from pretrained weights\cf1\highlight2 
\par \cf0\highlight0 New https://pypi.org/project/ultralytics/8.3.100 available \u55357?\u56835? Update with 'pip install -U ultralytics'\cf1\highlight2 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf3\highlight0 engine/trainer: \cf0 task=classify, mode=train, model=yolo11n-cls.yaml, data=data, epochs=50, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=models/best.pt, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=10, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train5\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... found 6101 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... found 714 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/test... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf0\highlight0 Overriding model.yaml nc=1000 with nc=4\cf1\highlight2 
\par 
\par \cf0\highlight0                    from  n    params  module                                       arguments\cf1\highlight2 
\par \cf0\highlight0   0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]\cf1\highlight2 
\par \cf0\highlight0   3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]\cf1\highlight2 
\par \cf0\highlight0   5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]\cf1\highlight2 
\par \cf0\highlight0   7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]\cf1\highlight2 
\par \cf0\highlight0   9                  -1  1    306882  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]\cf1\highlight2 
\par \cf0\highlight0  10                  -1  1    335364  ultralytics.nn.modules.head.Classify         [256, 4]\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary: 99 layers, 1,593,382 parameters, 1,593,382 gradients\cf1\highlight2 
\par \cf0\highlight0 Transferred 245/247 items from pretrained weights\cf1\highlight2 
\par \cf3\highlight0 AMP: \cf0 running Automatic Mixed Precision (AMP) checks...\cf1\highlight2 
\par \cf3\highlight0 AMP: \cf0 checks skipped \u9888?\cf4\highlight4\u65039?\cf0\highlight0 . Unable to load YOLO11n for AMP checks due to possible Ultralytics package modifications. Setting 'amp=True'. If you experience zero-mAP or NaN losses you can disable AMP with amp=False.\cf1\highlight2 
\par \cf3\highlight0 train: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... 6101 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 6101/6101 [00:00\cf1\highlight2 
\par \cf3\highlight0 val: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... 714 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 714/714 [00:00<?, ?it\cf1\highlight2 
\par \cf3\highlight0 optimizer:\cf0  SGD(lr=0.0001, momentum=0.937) with parameter groups 40 weight(decay=0.0), 47 weight(decay=0.0005), 43 bias(decay=0.0)\cf1\highlight2 
\par \cf0\highlight0 Image sizes 512 train, 512 val\cf1\highlight2 
\par \cf0\highlight0 Using 8 dataloader workers\cf1\highlight2 
\par \cf0\highlight0 Logging results to \b /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train5\cf1\highlight2\b0 
\par \cf0\highlight0 Starting training for 50 epochs...\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        1/50      1.07G      1.157          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:18<00:00, 20.23it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.18it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.427          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        2/50      1.14G     0.9693          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.53it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.28it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.637          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        3/50      1.14G     0.8023          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.25it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.51it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.711          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        4/50      1.14G     0.6813          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.43it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.94it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.754          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        5/50      1.14G     0.6014          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.19it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.60it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.775          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        6/50      1.14G     0.5727          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.91it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.49it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.773          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        7/50      1.14G      0.547          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.82it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.57it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.805          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        8/50      1.14G     0.5353          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.85it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.61it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.825          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        9/50      1.14G     0.5177          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 22.76it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.22it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.815          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       10/50      1.14G     0.5151          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.99it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.74it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.812          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       11/50      1.14G     0.5049          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.13it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.05it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.818          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       12/50      1.14G     0.4777          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 22.89it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.99it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.817          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       13/50      1.14G     0.4976          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.24it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.31it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.832          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       14/50      1.14G     0.4766          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.73it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.24it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.831          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       15/50      1.14G     0.4695          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.62it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.75it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.836          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       16/50      1.14G     0.4673          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.60it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.95it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.828          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       17/50      1.14G     0.4634          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.55it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.24it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.826          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       18/50      1.14G     0.4608          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.84it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.85it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.828          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       19/50      1.14G     0.4556          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.97it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.48it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.829          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       20/50      1.14G     0.4431          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.85it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.19it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.824          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       21/50      1.14G     0.4476          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.53it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.61it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.831          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       22/50      1.14G     0.4471          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.44it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.66it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.826          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       23/50      1.14G     0.4303          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.58it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.88it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.839          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       24/50      1.14G     0.4306          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.34it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.59it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.835          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       25/50      1.14G     0.4408          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.53it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.84it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.832          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       26/50      1.14G     0.4332          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.05it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.24it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.835          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       27/50      1.14G     0.4354          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.72it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.89it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.836          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       28/50      1.14G     0.4271          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.85it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 26.68it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.84          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       29/50      1.14G     0.4362          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.42it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.62it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.84          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       30/50      1.14G     0.4143          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.41it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.83it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.845          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       31/50      1.14G     0.4273          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.21it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.78it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.836          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       32/50      1.14G     0.4232          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.43it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.99it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.838          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       33/50      1.14G     0.4129          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.48it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 25.96it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.845          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       34/50      1.14G     0.4124          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.76it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.02it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.829          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       35/50      1.14G     0.4148          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.16it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.82it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.838          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       36/50      1.14G     0.4105          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.01it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.78it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.84          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       37/50      1.14G     0.4121          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.72it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.20it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.842          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       38/50      1.14G     0.4185          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.55it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 25.58it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.835          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       39/50      1.14G      0.411          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.04it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.93it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.843          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       40/50      1.14G     0.4141          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.09it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.77it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.845          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       41/50      1.14G     0.3983          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.56it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.34it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.847          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       42/50      1.14G     0.4083          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.75it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.38it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.84          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       43/50      1.14G     0.3966          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.20it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.67it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.846          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       44/50      1.14G     0.4006          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.84it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.16it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.84          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       45/50      1.14G     0.3911          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.78it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc:  83%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9614? | 19/23 [00:00<00:00, 27.78it/s]\cf1\highlight2 
\par \cf0\highlight0 Traceback (most recent call last):\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/train.py", line 7, in <module>\cf1\highlight2 
\par \cf0\highlight0     results = model.train(data="data", epochs=50, pretrained = True, imgsz=512,close_mosaic = 0, cls = 10, dropout = 0.3, optimizer = 'SGD', lr0 = 0.0001)\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/engine/model.py", line 791, in train\cf1\highlight2 
\par \cf0\highlight0     self.trainer.train()\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/engine/trainer.py", line 211, in train\cf1\highlight2 
\par \cf0\highlight0     self._do_train(world_size)\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/engine/trainer.py", line 438, in _do_train\cf1\highlight2 
\par \cf0\highlight0     self.metrics, self.fitness = self.validate()\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/engine/trainer.py", line 635, in validate\cf1\highlight2 
\par \cf0\highlight0     metrics = self.validator(self)\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context\cf1\highlight2 
\par \cf0\highlight0     return func(*args, **kwargs)\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/engine/validator.py", line 210, in __call__\cf1\highlight2 
\par \cf0\highlight0     batch = self.preprocess(batch)\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/models/yolo/classify/val.py", line 75, in preprocess\cf1\highlight2 
\par \cf0\highlight0     batch["cls"] = batch["cls"].to(self.device)\cf1\highlight2 
\par \cf0\highlight0 KeyboardInterrupt\cf1\highlight2 
\par \cf0\highlight0 Exception in thread Thread-3 (_pin_memory_loop):\cf1\highlight2 
\par \cf0\highlight0 Traceback (most recent call last):\cf1\highlight2 
\par \cf0\highlight0   File "/usr/lib/python3.10/threading.py", line 1016, in _bootstrap_inner\cf1\highlight2 
\par \cf0\highlight0     self.run()\cf1\highlight2 
\par \cf0\highlight0   File "/usr/lib/python3.10/threading.py", line 953, in run\cf1\highlight2 
\par \cf0\highlight0     self._target(*self._args, **self._kwargs)\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py", line 55, in _pin_memory_loop\cf1\highlight2 
\par \cf0\highlight0     do_one_step()\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py", line 32, in do_one_step\cf1\highlight2 
\par \cf0\highlight0     r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\cf1\highlight2 
\par \cf0\highlight0   File "/usr/lib/python3.10/multiprocessing/queues.py", line 122, in get\cf1\highlight2 
\par \cf0\highlight0     return _ForkingPickler.loads(res)\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py", line 496, in rebuild_storage_fd\cf1\highlight2 
\par \cf0\highlight0     fd = df.detach()\cf1\highlight2 
\par \cf0\highlight0   File "/usr/lib/python3.10/multiprocessing/resource_sharer.py", line 57, in detach\cf1\highlight2 
\par \cf0\highlight0     with _resource_sharer.get_connection(self._id) as conn:\cf1\highlight2 
\par \cf0\highlight0   File "/usr/lib/python3.10/multiprocessing/resource_sharer.py", line 86, in get_connection\cf1\highlight2 
\par \cf0\highlight0     c = Client(address, authkey=process.current_process().authkey)\cf1\highlight2 
\par \cf0\highlight0   File "/usr/lib/python3.10/multiprocessing/connection.py", line 502, in Client\cf1\highlight2 
\par \cf0\highlight0     c = SocketClient(address)\cf1\highlight2 
\par \cf0\highlight0   File "/usr/lib/python3.10/multiprocessing/connection.py", line 630, in SocketClient\cf1\highlight2 
\par \cf0\highlight0     s.connect(address)\cf1\highlight2 
\par \cf0\highlight0 FileNotFoundError: [Errno 2] No such file or directory\cf1\highlight2 
\par 
\par \cf0\highlight0 ubuntu@cv2:~/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics$ python3 train.py\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary: 99 layers, 2,869,258 parameters, 2,869,258 gradients\cf1\highlight2 
\par \cf0\highlight0 Transferred 236/247 items from pretrained weights\cf1\highlight2 
\par \cf0\highlight0 New https://pypi.org/project/ultralytics/8.3.100 available \u55357?\u56835? Update with 'pip install -U ultralytics'\cf1\highlight2 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf3\highlight0 engine/trainer: \cf0 task=classify, mode=train, model=yolo11n-cls.yaml, data=data, epochs=50, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=10, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train6\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... found 6101 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... found 714 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/test... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf0\highlight0 Overriding model.yaml nc=1000 with nc=4\cf1\highlight2 
\par 
\par \cf0\highlight0                    from  n    params  module                                       arguments\cf1\highlight2 
\par \cf0\highlight0   0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]\cf1\highlight2 
\par \cf0\highlight0   3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]\cf1\highlight2 
\par \cf0\highlight0   5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]\cf1\highlight2 
\par \cf0\highlight0   7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]\cf1\highlight2 
\par \cf0\highlight0   9                  -1  1    306882  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]\cf1\highlight2 
\par \cf0\highlight0  10                  -1  1    335364  ultralytics.nn.modules.head.Classify         [256, 4]\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary: 99 layers, 1,593,382 parameters, 1,593,382 gradients\cf1\highlight2 
\par \cf0\highlight0 Transferred 245/247 items from pretrained weights\cf1\highlight2 
\par \cf3\highlight0 AMP: \cf0 running Automatic Mixed Precision (AMP) checks...\cf1\highlight2 
\par \cf3\highlight0 AMP: \cf0 checks skipped \u9888?\cf5\highlight5\u65039?\cf0\highlight0 . Unable to load YOLO11n for AMP checks due to possible Ultralytics package modifications. Setting 'amp=True'. If you experience zero-mAP or NaN losses you can disable AMP with amp=False.\cf1\highlight2 
\par \cf3\highlight0 train: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... 6101 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 6101/6101 [00:00\cf1\highlight2 
\par \cf3\highlight0 val: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... 714 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 714/714 [00:00<?, ?it\cf1\highlight2 
\par \cf3\highlight0 optimizer:\cf0  SGD(lr=0.0001, momentum=0.937) with parameter groups 40 weight(decay=0.0), 47 weight(decay=0.0005), 43 bias(decay=0.0)\cf1\highlight2 
\par \cf0\highlight0 Image sizes 512 train, 512 val\cf1\highlight2 
\par \cf0\highlight0 Using 8 dataloader workers\cf1\highlight2 
\par \cf0\highlight0 Logging results to \b /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train6\cf1\highlight2\b0 
\par \cf0\highlight0 Starting training for 50 epochs...\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        1/50      1.08G      1.093         16        512:  42%|\u9608?\u9608?\u9608?\u9608?\u9615?     | 160/382 [00:09<00:13, 16.72it/s]\cf1\highlight2 
\par \cf0\highlight0 Traceback (most recent call last):\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/train.py", line 7, in <module>\cf1\highlight2 
\par \cf0\highlight0     results = model.train(data="data", epochs=50, pretrained = True, imgsz=512,close_mosaic = 0, cls = 10, dropout = 0.3, optimizer = 'SGD', lr0 = 0.0001)\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/engine/model.py", line 791, in train\cf1\highlight2 
\par \cf0\highlight0     self.trainer.train()\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/engine/trainer.py", line 211, in train\cf1\highlight2 
\par \cf0\highlight0     self._do_train(world_size)\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/engine/trainer.py", line 398, in _do_train\cf1\highlight2 
\par \cf0\highlight0     self.optimizer_step()\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/engine/trainer.py", line 622, in optimizer_step\cf1\highlight2 
\par \cf0\highlight0     self.ema.update(self.model)\cf1\highlight2 
\par \cf0\highlight0   File "/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/ultralytics/utils/torch_utils.py", line 660, in update\cf1\highlight2 
\par \cf0\highlight0     v += (1 - d) * msd[k].detach()\cf1\highlight2 
\par \cf0\highlight0 KeyboardInterrupt\cf1\highlight2 
\par 
\par \cf0\highlight0 ubuntu@cv2:~/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics$ python3 train.py\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary: 99 layers, 2,869,258 parameters, 2,869,258 gradients\cf1\highlight2 
\par \cf0\highlight0 Transferred 236/247 items from pretrained weights\cf1\highlight2 
\par \cf0\highlight0 New https://pypi.org/project/ultralytics/8.3.100 available \u55357?\u56835? Update with 'pip install -U ultralytics'\cf1\highlight2 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf3\highlight0 engine/trainer: \cf0 task=classify, mode=train, model=yolo11n-cls.yaml, data=data, epochs=50, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=10, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train7\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... found 6101 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... found 714 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/test... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf0\highlight0 Overriding model.yaml nc=1000 with nc=4\cf1\highlight2 
\par 
\par \cf0\highlight0                    from  n    params  module                                       arguments\cf1\highlight2 
\par \cf0\highlight0   0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]\cf1\highlight2 
\par \cf0\highlight0   3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]\cf1\highlight2 
\par \cf0\highlight0   5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]\cf1\highlight2 
\par \cf0\highlight0   7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]\cf1\highlight2 
\par \cf0\highlight0   9                  -1  1    306882  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]\cf1\highlight2 
\par \cf0\highlight0  10                  -1  1    335364  ultralytics.nn.modules.head.Classify         [256, 4]\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary: 99 layers, 1,593,382 parameters, 1,593,382 gradients\cf1\highlight2 
\par \cf0\highlight0 Transferred 245/247 items from pretrained weights\cf1\highlight2 
\par \cf3\highlight0 AMP: \cf0 running Automatic Mixed Precision (AMP) checks...\cf1\highlight2 
\par \cf3\highlight0 AMP: \cf0 checks skipped \u9888?\cf4\highlight4\u65039?\cf0\highlight0 . Unable to load YOLO11n for AMP checks due to possible Ultralytics package modifications. Setting 'amp=True'. If you experience zero-mAP or NaN losses you can disable AMP with amp=False.\cf1\highlight2 
\par \cf3\highlight0 train: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... 6101 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 6101/6101 [00:00\cf1\highlight2 
\par \cf3\highlight0 val: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... 714 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 714/714 [00:00<?, ?it\cf1\highlight2 
\par \cf3\highlight0 optimizer:\cf0  SGD(lr=0.0001, momentum=0.937) with parameter groups 40 weight(decay=0.0), 47 weight(decay=0.0005), 43 bias(decay=0.0)\cf1\highlight2 
\par \cf0\highlight0 Image sizes 512 train, 512 val\cf1\highlight2 
\par \cf0\highlight0 Using 8 dataloader workers\cf1\highlight2 
\par \cf0\highlight0 Logging results to \b /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train7\cf1\highlight2\b0 
\par \cf0\highlight0 Starting training for 50 epochs...\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        1/50      1.08G     0.9945          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:18<00:00, 20.69it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.24it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.674          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        2/50      1.14G     0.7569          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.89it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.07it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.734          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        3/50      1.14G     0.6527          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.02it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.05it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.759          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        4/50      1.14G     0.5835          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.65it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.16it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.803          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        5/50      1.14G     0.5409          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.43it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.20it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.819          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        6/50      1.14G     0.5169          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.55it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.96it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.843          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        7/50      1.14G     0.4974          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.36it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.88it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.846          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        8/50      1.14G     0.4744          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.05it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.52it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.833          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        9/50      1.14G     0.4652          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.51it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.02it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.814          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       10/50      1.14G     0.4582          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.02it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 26.65it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.832          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       11/50      1.14G     0.4584          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.55it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.87it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.843          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       12/50      1.14G     0.4294          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.27it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.87it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.843          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       13/50      1.14G     0.4451          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:14<00:00, 25.63it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.96it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.825          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       14/50      1.14G     0.4335          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.31it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.91it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.863          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       15/50      1.14G     0.4216          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.86it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.99it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.852          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       16/50      1.14G     0.4119          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.95it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.29it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.84          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       17/50      1.14G     0.4064          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.78it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.02it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.847          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       18/50      1.14G     0.4133          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.11it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.41it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.842          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       19/50      1.14G     0.3985          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:14<00:00, 25.80it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.92it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.846          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       20/50      1.14G     0.3971          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:14<00:00, 25.89it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.27it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.846          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       21/50      1.14G     0.4023          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.36it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.98it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.849          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       22/50      1.14G     0.3916          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.23it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.03it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.833          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       23/50      1.14G     0.3835          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.00it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.62it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.852          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       24/50      1.14G     0.3803          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.67it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.59it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.856          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       25/50      1.14G      0.384          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.31it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.44it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.852          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       26/50      1.14G     0.3789          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.27it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.23it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.857          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       27/50      1.14G     0.3876          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.14it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.45it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.854          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       28/50      1.14G     0.3772          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.35it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 32.10it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.863          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       29/50      1.14G     0.3831          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.15it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.46it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.856          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       30/50      1.14G     0.3597          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.17it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.59it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.853          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       31/50      1.14G     0.3684          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.66it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.80it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.857          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       32/50      1.14G     0.3646          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.22it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.68it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.853          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       33/50      1.14G     0.3617          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.82it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.91it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.859          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       34/50      1.14G      0.358          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.89it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.72it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.856          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       35/50      1.14G     0.3603          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.91it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.45it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.847          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       36/50      1.14G     0.3594          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.07it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.70it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.859          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       37/50      1.14G     0.3604          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.53it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.22it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.853          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       38/50      1.14G     0.3631          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.95it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.57it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.846          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       39/50      1.14G     0.3587          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.69it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.88it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.854          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       40/50      1.14G     0.3568          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.05it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.12it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.857          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       41/50      1.14G     0.3436          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.93it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 32.36it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.853          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       42/50      1.14G      0.354          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.86it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.73it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.859          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       43/50      1.14G     0.3406          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.72it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.05it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.856          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       44/50      1.14G     0.3466          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.76it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.69it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.852          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       45/50      1.14G     0.3304          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.10it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.93it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.857          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       46/50      1.14G     0.3561          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.01it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 32.20it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.856          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       47/50      1.14G     0.3449          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.04it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 32.81it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.856          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       48/50      1.14G     0.3462          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.87it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.62it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.859          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       49/50      1.14G     0.3468          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.16it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.67it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.854          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       50/50      1.14G     0.3446          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.09it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.35it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.859          1\cf1\highlight2 
\par 
\par \cf0\highlight0 50 epochs completed in 0.231 hours.\cf1\highlight2 
\par \cf0\highlight0 Optimizer stripped from /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train7/weights/last.pt, 3.3MB\cf1\highlight2 
\par \cf0\highlight0 Optimizer stripped from /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train7/weights/best.pt, 3.3MB\cf1\highlight2 
\par 
\par \cf0\highlight0 Validating /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train7/weights/best.pt...\cf1\highlight2 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary (fused): 60 layers, 1,588,302 parameters, 0 gradients\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/train... found 6101 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/val... found 714 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/data/test... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:01<00:00, 21.40it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.863          1\cf1\highlight2 
\par \cf0\highlight0 Speed: 0.4ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\cf1\highlight2 
\par \cf0\highlight0 Results saved to \b /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train7\cf1\highlight2\b0 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary (fused): 60 layers, 1,588,302 parameters, 0 gradients\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/vald/train... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/vald/val... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  None...\cf1\highlight2 
\par \cf3\highlight0 val: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/vald/val... 357 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 357/357 [00:00<?, ?it\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:01<00:00, 18.31it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.88          1\cf1\highlight2 
\par \cf0\highlight0 Speed: 0.8ms preprocess, 1.1ms inference, 0.0ms loss, 0.0ms postprocess per image\cf1\highlight2 
\par \cf0\highlight0 Results saved to \b /home/ubuntu/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics/runs/classify/train72\cf1\highlight2\b0 
\par \cf0\highlight0 ubuntu@cv2:~/cv_runs/cv/cv_runs/EA_SA_CA/ultralytics$\cf1\highlight2 
\par \pard\cf0\highlight0\f1\fs16 
\par }
 