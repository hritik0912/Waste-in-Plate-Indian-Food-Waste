{\rtf1\ansi\ansicpg1252\deff0\deflang1033{\fonttbl{\f0\fmodern Consolas;}{\f1\fnil\fcharset129 Courier New;}}
{\colortbl ;\red20\green20\blue20;\red142\green142\blue142;\red18\green124\blue155;\red235\green215\blue127;\red157\green157\blue157;}
\viewkind4\uc1\pard\f0\fs20 ubuntu@cv2:~/cv_runs/cv/cv_runs/CA_SA/ultralytics$ cd ..\cf1\highlight2 
\par \cf0\highlight0 ubuntu@cv2:~/cv_runs/cv/cv_runs/CA_SA$ cd ..\cf1\highlight2 
\par \cf0\highlight0 ubuntu@cv2:~/cv_runs/cv/cv_runs$ cd SA_EA/ultralytics/\cf1\highlight2 
\par \cf0\highlight0 ubuntu@cv2:~/cv_runs/cv/cv_runs/SA_EA/ultralytics$ python3 train.py\cf1\highlight2 
\par \cf0\highlight0 Creating new Ultralytics Settings v0.0.6 file \u9989?\cf1\highlight2 
\par \cf0\highlight0 View Ultralytics Settings with 'yolo settings' or at '/home/ubuntu/.config/Ultralytics/settings.json'\cf1\highlight2 
\par \cf0\highlight0 Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary: 94 layers, 2,865,018 parameters, 2,865,018 gradients\cf1\highlight2 
\par \cf0\highlight0 Transferred 236/243 items from pretrained weights\cf1\highlight2 
\par \cf0\highlight0 New https://pypi.org/project/ultralytics/8.3.100 available \u55357?\u56835? Update with 'pip install -U ultralytics'\cf1\highlight2 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf3\highlight0 engine/trainer: \cf0 task=classify, mode=train, model=yolo11n-cls.yaml, data=data, epochs=50, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=10, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/runs/classify/train\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/data/train... found 6101 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/data/val... found 714 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/data/test... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf0\highlight0 Overriding model.yaml nc=1000 with nc=4\cf1\highlight2 
\par 
\par \cf0\highlight0                    from  n    params  module                                       arguments\cf1\highlight2 
\par \cf0\highlight0   0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]\cf1\highlight2 
\par \cf0\highlight0   3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]\cf1\highlight2 
\par \cf0\highlight0   5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]\cf1\highlight2 
\par \cf0\highlight0   7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]\cf1\highlight2 
\par \cf0\highlight0   8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]\cf1\highlight2 
\par \cf0\highlight0   9                  -1  1    302642  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]\cf1\highlight2 
\par \cf0\highlight0  10                  -1  1    335364  ultralytics.nn.modules.head.Classify         [256, 4]\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary: 94 layers, 1,589,142 parameters, 1,589,142 gradients\cf1\highlight2 
\par \cf0\highlight0 Transferred 241/243 items from pretrained weights\cf1\highlight2 
\par \cf3\highlight0 AMP: \cf0 running Automatic Mixed Precision (AMP) checks...\cf1\highlight2 
\par \cf3\highlight0 AMP: \cf0 checks skipped \u9888?\cf4\highlight5\u65039?\cf0\highlight0 . Unable to load YOLO11n for AMP checks due to possible Ultralytics package modifications. Setting 'amp=True'. If you experience zero-mAP or NaN losses you can disable AMP with amp=False.\cf1\highlight2 
\par \cf3\highlight0 train: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/data/train... 6101 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 6101/6101 [00:02<00\cf1\highlight2 
\par \cf3\highlight0 train: \cf0 New cache created: /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/data/train.cache\cf1\highlight2 
\par \cf3\highlight0 val: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/data/val... 714 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 714/714 [00:00<00:00, 22\cf1\highlight2 
\par \cf3\highlight0 val: \cf0 New cache created: /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/data/val.cache\cf1\highlight2 
\par \cf3\highlight0 optimizer:\cf0  SGD(lr=0.0001, momentum=0.937) with parameter groups 40 weight(decay=0.0), 45 weight(decay=0.0005), 41 bias(decay=0.0)\cf1\highlight2 
\par \cf0\highlight0 Image sizes 512 train, 512 val\cf1\highlight2 
\par \cf0\highlight0 Using 8 dataloader workers\cf1\highlight2 
\par \cf0\highlight0 Logging results to \b /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/runs/classify/train\cf1\highlight2\b0 
\par \cf0\highlight0 Starting training for 50 epochs...\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        1/50      0.98G       1.33         16        512:   0%|          | 1/382 [00:01<12:07,  1.91s/it]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        1/50      1.17G      1.198         16        512:  11%|\u9608?         | 42/382 [00:03<00:14, 23.15it/s]Downloading https://ultralytics.com/assets/Arial.ttf to '/home/ubuntu/.config/Ultralytics/Arial.ttf'...\cf1\highlight2 
\par \cf0\highlight0 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 755k/755k [00:00<00:00, 22.2MB/s]\cf1\highlight2 
\par \cf0\highlight0        1/50      1.18G     0.9735          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:18<00:00, 21.12it/s]       | 0.00/755k [00:00<?, ?B/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 26.89it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.675          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        2/50      1.18G     0.7448          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.23it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.93it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.723          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        3/50      1.18G     0.6335          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.04it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.89it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.755          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        4/50      1.18G     0.5678          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.79it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.23it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.805          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        5/50      1.18G     0.5298          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.36it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.76it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.817          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        6/50      1.18G     0.5108          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.67it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.20it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.835          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        7/50      1.18G     0.4913          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.18it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.17it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.843          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        8/50      1.18G     0.4728          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.58it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.15it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.839          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0        9/50      1.18G     0.4614          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.38it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 26.04it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.822          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       10/50      1.18G     0.4581          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.93it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.58it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.836          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       11/50      1.18G      0.454          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.46it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.10it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.846          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       12/50      1.18G     0.4265          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.79it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.96it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.845          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       13/50      1.18G     0.4381          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.37it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 26.94it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.838          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       14/50      1.18G     0.4285          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.51it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.24it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.861          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       15/50      1.18G     0.4211          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.53it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.78it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.849          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       16/50      1.18G     0.4115          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.36it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.86it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.85          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       17/50      1.18G     0.4088          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.89it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.29it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.849          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       18/50      1.18G     0.4128          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.88it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.55it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.849          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       19/50      1.18G     0.3966          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.00it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.92it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.85          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       20/50      1.18G     0.3946          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.81it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.27it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.852          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       21/50      1.18G     0.3985          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.81it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.22it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.853          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       22/50      1.18G     0.3927          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.76it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.59it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.84          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       23/50      1.18G     0.3802          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.23it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.05it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.857          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       24/50      1.18G     0.3758          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.66it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.59it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.854          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       25/50      1.18G     0.3764          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.98it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.70it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.85          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       26/50      1.18G     0.3661          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.02it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.26it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.857          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       27/50      1.18G     0.3825          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.84it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.74it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.854          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       28/50      1.18G     0.3734          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.79it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.07it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.864          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       29/50      1.18G     0.3799          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.92it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.93it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.847          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       30/50      1.18G     0.3576          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.52it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.28it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.852          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       31/50      1.18G     0.3655          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.57it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.09it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.853          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       32/50      1.18G     0.3618          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.75it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.51it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.86          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       33/50      1.18G     0.3553          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.66it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.97it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.857          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       34/50      1.18G     0.3584          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.46it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.53it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.856          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       35/50      1.18G     0.3571          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.93it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.63it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.847          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       36/50      1.18G     0.3634          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.53it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.77it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.859          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       37/50      1.18G     0.3582          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:16<00:00, 23.83it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.09it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.852          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       38/50      1.18G     0.3582          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.68it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.20it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.846          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       39/50      1.18G     0.3559          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 25.15it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.34it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.857          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       40/50      1.18G     0.3531          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.04it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 27.59it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.856          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       41/50      1.18G     0.3472          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 23.93it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.73it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.853          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       42/50      1.18G     0.3561          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.69it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.21it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.861          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       43/50      1.18G     0.3382          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.86it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.09it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.857          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       44/50      1.18G     0.3421          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.48it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 31.86it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.85          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       45/50      1.18G     0.3266          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.73it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.58it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.854          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       46/50      1.18G     0.3484          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.60it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.10it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.859          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       47/50      1.18G     0.3386          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.67it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.21it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.857          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       48/50      1.18G     0.3437          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.65it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 28.64it/s]\cf1\highlight2 
\par \cf0\highlight0                    all       0.86          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       49/50      1.18G     0.3429          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.75it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 29.11it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.853          1\cf1\highlight2 
\par 
\par \cf0\highlight0       Epoch    GPU_mem       loss  Instances       Size\cf1\highlight2 
\par \cf0\highlight0   0%|          | 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: upsample_bilinear2d_aa_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:83.)\cf1\highlight2 
\par \cf0\highlight0   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\cf1\highlight2 
\par \cf0\highlight0       50/50      1.18G     0.3404          5        512: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 382/382 [00:15<00:00, 24.58it/s]\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:00<00:00, 30.28it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.859          1\cf1\highlight2 
\par 
\par \cf0\highlight0 50 epochs completed in 0.232 hours.\cf1\highlight2 
\par \cf0\highlight0 Optimizer stripped from /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/runs/classify/train/weights/last.pt, 3.3MB\cf1\highlight2 
\par \cf0\highlight0 Optimizer stripped from /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/runs/classify/train/weights/best.pt, 3.3MB\cf1\highlight2 
\par 
\par \cf0\highlight0 Validating /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/runs/classify/train/weights/best.pt...\cf1\highlight2 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary (fused): 55 layers, 1,584,062 parameters, 0 gradients\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/data/train... found 6101 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/data/val... found 714 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/data/test... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:01<00:00, 21.93it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.864          1\cf1\highlight2 
\par \cf0\highlight0 Speed: 0.3ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\cf1\highlight2 
\par \cf0\highlight0 Results saved to \b /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/runs/classify/train\cf1\highlight2\b0 
\par \cf0\highlight0 Ultralytics 8.3.99 \u55357?\u56960? Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40326MiB)\cf1\highlight2 
\par \cf0\highlight0 YOLO11n-cls summary (fused): 55 layers, 1,584,062 parameters, 0 gradients\cf1\highlight2 
\par \cf3\highlight0 train:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/vald/train... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 val:\cf0  /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/vald/val... found 357 images in 4 classes \u9989?\cf1\highlight2 
\par \cf3\highlight0 test:\cf0  None...\cf1\highlight2 
\par \cf3\highlight0 val: \cf0 Scanning /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/vald/val... 357 images, 0 corrupt: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 357/357 [00:00<00:00, 25\cf1\highlight2 
\par \cf3\highlight0 val: \cf0 New cache created: /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/vald/val.cache\cf1\highlight2 
\par \cf0\highlight0                classes   top1_acc   top5_acc: 100%|\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?\u9608?| 23/23 [00:01<00:00, 13.61it/s]\cf1\highlight2 
\par \cf0\highlight0                    all      0.882          1\cf1\highlight2 
\par \cf0\highlight0 Speed: 0.8ms preprocess, 1.5ms inference, 0.0ms loss, 0.0ms postprocess per image\cf1\highlight2 
\par \cf0\highlight0 Results saved to \b /home/ubuntu/cv_runs/cv/cv_runs/SA_EA/ultralytics/runs/classify/train2\cf1\highlight2\b0 
\par \cf0\highlight0 ubuntu@cv2:~/cv_runs/cv/cv_runs/SA_EA/ultralytics$\cf1\highlight2 
\par \pard\cf0\highlight0\f1\fs16 
\par }
 